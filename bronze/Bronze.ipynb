{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a21cc507-db39-47d5-b2f2-9bcf178c5cf8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Select Catalog and Schema"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- BRONZE LAYER INGESTION LOGIC\n",
    "-- Select Catalog and Schema\n",
    "-- Set the working environment using SQL, pointing to the relevant catalog and schema for saving the Bronze table.\n",
    "\n",
    "use catalog vsqproject;\n",
    "use schema bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2d6d81e-f33f-4c68-8608-265e6aeeca87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afb3e58b-e791-4541-b36e-dbe0097f5b4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59500ac5-b70b-4d9e-a88d-9069f3438c26",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Retrieve Secure Creds from Azure Key Vault"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve Secure Creds from Key Vault\n",
    "# This avoids hardcoding sensitive credentials.             \n",
    "password = dbutils.secrets.get(scope=\"krsna-scope\", key=\"postgresdbpass\")\n",
    "username = dbutils.secrets.get(scope=\"krsna-scope\", key=\"dbusername\")\n",
    "jdbc_url = dbutils.secrets.get(scope=\"krsna-scope\", key=\"jdbcurl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d6ba720-cb06-4330-9b3f-d0e120075e0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Summary \n",
    "--\n",
    "In this notebook, we connect securely to a Azure SQL Server database using credentials stored in Azure Key Vault.\n",
    "We ingest raw product data into our Bronze layer, which acts as the raw landing zone. As part of this process, approximately 600 rows are ingested into the table, preserving the original structure and content.\n",
    "This helps maintain data integrity for auditability and traceability before applying any transformations in the Silver layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8cd4c97-a12e-46b3-bd92-7e232c369bff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Store Table"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').option('header','true').load('s3://sourcekrsna/vsqproject/raw_stores/raw_stores.csv')\n",
    "# df.show()\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"raw_stores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddbabe00-663c-4e91-9e6e-bc3dbc3e5c90",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Products Table"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "connection_properties = {\n",
    "  \"user\": username,\n",
    "  \"password\": password,\n",
    "  \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df = spark.read.jdbc(url=jdbc_url, table=\"vsqproject.products\", properties=connection_properties)\n",
    "df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"raw_products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4b7272-0c5e-4855-b8e2-e6358f31bb24",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Customer Table"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://my.api.mockaroo.com/raw_customers.json?key=519b2bf0\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "file_path = \"s3://sourcekrsna/vsqproject/raw_customers/raw_customers.json\"\n",
    "json_data = json.dumps(data, indent = 4)\n",
    "dbutils.fs.put(file_path, json_data, overwrite=True)\n",
    "\n",
    "df = spark.read.format(\"json\").option('multiLine', True).load(\"s3://sourcekrsna/vsqproject/raw_customers/raw_customers.json\")\n",
    "df = df.withColumn(\"customerid\", F.col('customerid').cast('string'))\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"raw_customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1bc1b2d-cd3b-44ee-bb59-9ff2c0fcd6c3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Sales Table"
    }
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.readStream\n",
    "    .format('cloudFiles')\n",
    "    .option('cloudFiles.format', 'csv')\n",
    "    .option('cloudFiles.schemaLocation', 's3://bronzebucketkrsna/vsqproject/raw_sales/schema/')\n",
    "    .load('s3://sourcekrsna/vsqproject/raw_sales/')\n",
    ")\n",
    "\n",
    "df_clean = df.drop('_rescued_data')\n",
    "\n",
    "df_clean.writeStream \\\n",
    "    .format('delta') \\\n",
    "    .option('checkpointLocation', 's3://bronzebucketkrsna/vsqproject/raw_sales/checkpoint/') \\\n",
    "    .trigger(once=True) \\\n",
    "    .table('vsqproject.bronze.raw_sales')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1856619818682567,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
