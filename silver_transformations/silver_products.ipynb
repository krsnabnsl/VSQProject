{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69728f1e-c211-46fd-883a-413bba22320a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- SILVER LAYER TRANSFORMATION LOGIC\n",
    "\n",
    "-- Step 1: Select Catalog and Schema \n",
    "-- Set the working environment using SQL, pointing to the relevant catalog and schema \n",
    "-- where the bronze table will be saved.\n",
    "\n",
    "USE CATALOG vsqproject;\n",
    "USE SCHEMA bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5637869b-3e10-4b45-9a3a-329764274060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# source_table = dbutils.widgets.get(\"source_table\")\n",
    "# sink_table = dbutils.widgets.get(\"sink_table\")\n",
    "source_table = \"raw_products\"\n",
    "sink_table = \"products_silver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0efc3b5d-956a-4aa4-971e-237be9491335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Read Raw Bronze Layer Data\n",
    "# Load the raw 'products' Delta table from the Bronze layer into a DataFrame.\n",
    "# This acts as our source data for the Silver layer transformation process.\n",
    "\n",
    "df= spark.table(source_table)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a565097a-d100-4293-9329-372a3cbde084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp,trim,mean\n",
    "\n",
    "# Step 3: Remove rows with nulls in essential columns\n",
    "# Filter: not null AND not empty (after trimming spaces)\n",
    "filteredDf = df.filter(col(\"product_id\").isNotNull() & (trim(col(\"product_id\")) != \"\"))\n",
    "df_silver = filteredDf.withColumn(\"price\", filteredDf[\"price\"].cast(\"double\"))\n",
    "\n",
    "# Step 4: Replace remaining nulls with default values\n",
    "# If any nulls are still present:\n",
    "# - Replace missing price with the average price from the dataset\n",
    "# - Replace missing product_name with 'Unknown'\n",
    "# - Replace missing category with 'Miscellaneous'\n",
    "mean_price_row = df_silver.select(mean(\"price\")).alias(\"avg_price\").first()[0] or 0.0\n",
    "\n",
    "# Replace nulls with defaults\n",
    "df_silver = df_silver.fillna({\n",
    "    \"price\": mean_price_row,\n",
    "    \"productname\": \"Unknown\",\n",
    "    \"brand\": \"UnknownBrand\",\n",
    "    \"category\": \"Miscellaneous\"\n",
    "})\n",
    "\n",
    "# Step 5: Drop duplicate rows based on product_id\n",
    "# This ensures each product appears only once in the dataset.\n",
    "df_silver = df_silver.dropDuplicates(['product_id'])\n",
    "\n",
    "\n",
    "# Step 6: Filter out invalid prices\n",
    "# Remove any products where price is zero or negative, since they are considered invalid for business reporting.\n",
    "df_silver = df_silver.filter(col('price') > 0)\n",
    "\n",
    "# Step 7: Add last updated timestamp\n",
    "# Add a new column 'last_updated' to capture the date and time when the data was processed.\n",
    "df_silver = df_silver.withColumn(\"last_updated\", current_timestamp())\n",
    "\n",
    "\n",
    "# Step 8 : Save transformed data to the Silver layer\n",
    "# Write the data as a Delta table in the 'silver' schema, overwriting any previous version.\n",
    "df_silver.write.format(\"delta\").option(\"mergeSchema\", \"true\").partitionBy('category').mode(\"overwrite\").saveAsTable(f\"vsqproject.silver.{sink_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3089f21f-2055-4a4d-9b9a-89d628f1a7f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 11: Verify the Silver Table Load\n",
    "# Run a query to ensure that the Silver layer data was written successfully.\n",
    "\n",
    "# df = spark.sql(f\"select * from vsqproject.silver.{sink_table}\")\n",
    "# df.printSchema()\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "646fe057-0cf1-499e-87cf-8f1d4024eed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Summary\n",
    "=============\n",
    "\n",
    "In this Silver layer process:\n",
    "\n",
    "Source: Data is read from the Bronze layer Delta table.\n",
    "\n",
    "**Cleaning:**\n",
    "Removed records where product_id was null or empty (after trimming spaces).\n",
    "\n",
    "Filled missing values:\n",
    "\n",
    "price → replaced with average price from dataset.\n",
    "\n",
    "product_name → replaced with \"Unknown\".\n",
    "\n",
    "category → replaced with \"Miscellaneous\".\n",
    "\n",
    "Dropped duplicate products based on product_id.\n",
    "\n",
    "Removed records with non-positive prices (≤ 0).\n",
    "\n",
    "**Enrichment**:\n",
    "\n",
    "Added last_updated timestamp to capture processing time.\n",
    "\n",
    "**Output:**\n",
    "Saved the cleaned and enriched dataset as vsqproject.silver.Products_silver in Delta format.\n",
    "\n",
    "This ensures the Silver table contains accurate, validated, and timestamped data, ready for analytics, reporting, or further transformation in the Gold layer.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1856619818682613,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_products",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
